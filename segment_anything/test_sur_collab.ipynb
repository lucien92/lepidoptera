{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1ae39ff",
      "metadata": {
        "id": "a1ae39ff"
      },
      "source": [
        "# Object masks from prompts with SAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a4b25c",
      "metadata": {
        "id": "b4a4b25c"
      },
      "source": [
        "The Segment Anything Model (SAM) predicts object masks given prompts that indicate the desired object. The model first converts the image into an image embedding that allows high quality masks to be efficiently produced from a prompt. \n",
        "\n",
        "The `SamPredictor` class provides an easy interface to the model for prompting the model. It allows the user to first set an image using the `set_image` method, which calculates the necessary image embeddings. Then, prompts can be provided via the `predict` method to efficiently predict masks from those prompts. The model can take as input both point and box prompts, as well as masks from the previous iteration of prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644532a8",
      "metadata": {
        "id": "644532a8"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fabfee",
      "metadata": {
        "id": "07fabfee"
      },
      "source": [
        "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_collab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "91dd9a89",
      "metadata": {
        "id": "91dd9a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2470a169-3a15-4391-d1ff-b22d68596ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.0+cu118\n",
            "Torchvision version: 0.15.1+cu118\n",
            "CUDA is available: True\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-0pumvf89\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-0pumvf89\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 3518c86b78b3bc9cf4fbe3d18e682fad1c79dc51\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "--2023-04-13 19:37:11--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.35.8.29, 13.35.8.51, 13.35.8.35, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.35.8.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375042383 (358M) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_b_01ec64.pth’\n",
            "\n",
            "sam_vit_b_01ec64.pt 100%[===================>] 357.67M   249MB/s    in 1.4s    \n",
            "\n",
            "2023-04-13 19:37:13 (249 MB/s) - ‘sam_vit_b_01ec64.pth’ saved [375042383/375042383]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    \n",
        "#!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be845da",
      "metadata": {
        "id": "0be845da"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33681dd1",
      "metadata": {
        "id": "33681dd1"
      },
      "source": [
        "Necessary imports and helper functions for displaying points, boxes, and masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "69b28288",
      "metadata": {
        "id": "69b28288"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "29bc90d5",
      "metadata": {
        "id": "29bc90d5"
      },
      "outputs": [],
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "    \n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
        "    \n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement du modèle"
      ],
      "metadata": {
        "id": "pBSPo31d7ceu"
      },
      "id": "pBSPo31d7ceu"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
        "model_type = \"vit_b\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "PFYYjg7F7ezw"
      },
      "id": "PFYYjg7F7ezw",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des données"
      ],
      "metadata": {
        "id": "4aAX4BQB6zh-"
      },
      "id": "4aAX4BQB6zh-"
    },
    {
      "cell_type": "markdown",
      "source": [
        " **TEST EN REPRENANT LES IMAGES DÉJÀ ANNOTÉES PAR YOLO**"
      ],
      "metadata": {
        "id": "wrSxGhLrDxbv"
      },
      "id": "wrSxGhLrDxbv"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf lepidoptera\n",
        "!git clone https://github.com/lucien92/lepidoptera/"
      ],
      "metadata": {
        "id": "Kxh5HKVN62FP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c80fd89-a792-4b3e-e3ab-dbb32e608aad"
      },
      "id": "Kxh5HKVN62FP",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lepidoptera'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
            "remote: Total 248 (delta 5), reused 248 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (248/248), 13.27 MiB | 18.56 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from segment_anything import build_sam, SamPredictor, sam_model_registry"
      ],
      "metadata": {
        "id": "9ic9VyDBED1P"
      },
      "id": "9ic9VyDBED1P",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####  parameters #####\n",
        "csv_path = \"/content/lepidoptera/segment_anything/result_2023-04-05 13:46:11.874005\" #ici mettre le csv généré par le yolo (pour l'instant Amegilla quadrifasciata mais à remplacer par lépido)\n",
        "\n",
        "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
        "model_type = \"vit_b\"\n",
        "\n",
        "device = \"cuda\"\n",
        "#####  parameters #####\n",
        "!mkdir \"/content/lepidoptera/segment_anything/output\"\n",
        "output_path = \"/content/lepidoptera/segment_anything/output\""
      ],
      "metadata": {
        "id": "nDvdRPCFEGkt"
      },
      "id": "nDvdRPCFEGkt",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####  util functions #####\n",
        "\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
        "\n",
        "#####  predict #####\n",
        "\n",
        "def predict(img_path, sam_checkpoint, model_type, device, output_path, input_point): #, box\n",
        "\n",
        "    image_name = (img_path.split(os.path.sep)[-1]).split('.')[0]\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "    sam.to(device=device)\n",
        "\n",
        "    predictor = SamPredictor(sam)\n",
        "    predictor.set_image(image)\n",
        "\n",
        "    input_point = input_point\n",
        "    input_label = np.array([1])\n",
        "\n",
        "    masks, scores, logits = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        multimask_output=False,\n",
        "        # box=box\n",
        "\n",
        "    )\n",
        "\n",
        "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
        "        plt.figure(figsize=(100,100))\n",
        "        plt.imshow(image)\n",
        "        show_mask(mask, plt.gca())\n",
        "        show_points(input_point, input_label, plt.gca())\n",
        "        # show_box(box, plt.gca())\n",
        "        plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
        "        plt.axis('on')\n",
        "        plt.savefig(f\"{output_path}/\"+ image_name + \".png\")\n",
        "\n",
        "def read_csv(csv_path):\n",
        "\n",
        "    with open(csv_path, \"r\") as f:\n",
        "\n",
        "        img_paths = []\n",
        "        img_bbox = []\n",
        "        img_bbox_centers = []\n",
        "\n",
        "        for line in f:\n",
        "            line = line.split(\",\")\n",
        "\n",
        "            img_path = line[0]\n",
        "            img_paths.append(img_path)\n",
        "\n",
        "            bbox= np.array([float(line[1]), float(line[2]), float(line[3]), float(line[4])])\n",
        "            img_bbox.append(bbox)\n",
        "\n",
        "            bbox_center = np.array([[(bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2]])\n",
        "            img_bbox_centers.append(bbox_center)\n",
        "\n",
        "    return img_paths, img_bbox, img_bbox_centers"
      ],
      "metadata": {
        "id": "9abTYdjgEcze"
      },
      "id": "9abTYdjgEcze",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    img_paths, img_bbox, img_bbox_centers = read_csv(csv_path)\n",
        "\n",
        "    for i, img_path in enumerate(img_paths):\n",
        "\n",
        "        bbox_center = img_bbox_centers[i]\n",
        "        print(img_path)\n",
        "        #bbox = img_bbox[i]\n",
        "        predict(img_path, sam_checkpoint, model_type, device, output_path, bbox_center)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uttnN3tiEhQ-",
        "outputId": "d8a7b079-d9ee-4406-f0a4-5698962d70c6"
      },
      "id": "uttnN3tiEhQ-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lepidoptera  sam_vit_b_01ec64.pth  sam_vit_h_4b8939.pth.1\n",
            "sample_data  sam_vit_h_4b8939.pth\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata48084.jpg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata80637.jpeg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata89995.jpg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata83743.jpg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata91602.jpg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata91602.jpg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata43569.jpeg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata46140.jpeg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata88608.jpeg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata91377.jpeg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata88628.jpg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata36967.jpeg\n",
            "/content/lepidoptera/segment_anything/Amegilla quadrifasciata/Amegilla quadrifasciata14018.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#on veut accéder aux résultats inscrits dans \"/content/lepidoptera/segment_anything/output\"\n",
        "!zip -r lepidoptere.zip /content/lepidoptera/segment_anything/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gPTcqrwIBm3",
        "outputId": "59bea7eb-f5b3-4e5e-f42c-89e1fedb4e0d"
      },
      "id": "6gPTcqrwIBm3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/lepidoptera/segment_anything/output/ (stored 0%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata91602.png (deflated 40%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata48084.png (deflated 46%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata80637.png (deflated 54%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata88628.png (deflated 41%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata88608.png (deflated 49%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata89995.png (deflated 32%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata46140.png (deflated 44%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata43569.png (deflated 53%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata36967.png (deflated 57%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata83743.png (deflated 52%)\n",
            "  adding: content/lepidoptera/segment_anything/output/Amegilla quadrifasciata91377.png (deflated 37%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8DghwAvJw6o",
        "outputId": "d4adc339-a624-463a-a763-5e7b0f8d3816"
      },
      "id": "a8DghwAvJw6o",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lepidoptera\t sample_data\t       sam_vit_h_4b8939.pth\n",
            "lepidoptere.zip  sam_vit_b_01ec64.pth  sam_vit_h_4b8939.pth.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}